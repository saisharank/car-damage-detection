{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Left and Right.ipynb","provenance":[{"file_id":"1f1N4lg09uA64TNtIp3epuDoB4uJqf_rN","timestamp":1573742614809},{"file_id":"1hR0xl7pfTkJOLrjV7sKT6S4JjgsOdy_u","timestamp":1572881632572}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YKoR8zSgjAlQ","colab_type":"code","outputId":"e0b03002-be3a-4264-b2ad-f2b7e026b190","executionInfo":{"status":"ok","timestamp":1574162085738,"user_tz":-330,"elapsed":38671,"user":{"displayName":"Saisharan K","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAJ1nwvSoqQU5GIyVGpz9V4iq_C1Cv8tEYDhBHRPw=s64","userId":"06407441015676207791"}},"colab":{"base_uri":"https://localhost:8080/","height":323}},"source":["!git clone https://github.com/saisharank/Left-and-Right\n","!git clone https://github.com/tensorflow/models.git\n","!git clone https://github.com/kwotsin/create_tfrecords"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Cloning into 'Left-and-Right'...\n","remote: Enumerating objects: 532, done.\u001b[K\n","remote: Counting objects:   0% (1/532)\u001b[K\rremote: Counting objects:   1% (6/532)\u001b[K\rremote: Counting objects:   2% (11/532)\u001b[K\rremote: Counting objects:   3% (16/532)\u001b[K\rremote: Counting objects:   4% (22/532)\u001b[K\rremote: Counting objects:   5% (27/532)\u001b[K\rremote: Counting objects:   6% (32/532)\u001b[K\rremote: Counting objects:   7% (38/532)\u001b[K\rremote: Counting objects:   8% (43/532)\u001b[K\rremote: Counting objects:   9% (48/532)\u001b[K\rremote: Counting objects:  10% (54/532)\u001b[K\rremote: Counting objects:  11% (59/532)\u001b[K\rremote: Counting objects:  12% (64/532)\u001b[K\rremote: Counting objects:  13% (70/532)\u001b[K\rremote: Counting objects:  14% (75/532)\u001b[K\rremote: Counting objects:  15% (80/532)\u001b[K\rremote: Counting objects:  16% (86/532)\u001b[K\rremote: Counting objects:  17% (91/532)\u001b[K\rremote: Counting objects:  18% (96/532)\u001b[K\rremote: Counting objects:  19% (102/532)\u001b[K\rremote: Counting objects:  20% (107/532)\u001b[K\rremote: Counting objects:  21% (112/532)\u001b[K\rremote: Counting objects:  22% (118/532)\u001b[K\rremote: Counting objects:  23% (123/532)\u001b[K\rremote: Counting objects:  24% (128/532)\u001b[K\rremote: Counting objects:  25% (133/532)\u001b[K\rremote: Counting objects:  26% (139/532)\u001b[K\rremote: Counting objects:  27% (144/532)\u001b[K\rremote: Counting objects:  28% (149/532)\u001b[K\rremote: Counting objects:  29% (155/532)\u001b[K\rremote: Counting objects:  30% (160/532)\u001b[K\rremote: Counting objects:  31% (165/532)\u001b[K\rremote: Counting objects:  32% (171/532)\u001b[K\rremote: Counting objects:  33% (176/532)\u001b[K\rremote: Counting objects:  34% (181/532)\u001b[K\rremote: Counting objects:  35% (187/532)\u001b[K\rremote: Counting objects:  36% (192/532)\u001b[K\rremote: Counting objects:  37% (197/532)\u001b[K\rremote: Counting objects:  38% (203/532)\u001b[K\rremote: Counting objects:  39% (208/532)\u001b[K\rremote: Counting objects:  40% (213/532)\u001b[K\rremote: Counting objects:  41% (219/532)\u001b[K\rremote: Counting objects:  42% (224/532)\u001b[K\rremote: Counting objects:  43% (229/532)\u001b[K\rremote: Counting objects:  44% (235/532)\u001b[K\rremote: Counting objects:  45% (240/532)\u001b[K\rremote: Counting objects:  46% (245/532)\u001b[K\rremote: Counting objects:  47% (251/532)\u001b[K\rremote: Counting objects:  48% (256/532)\u001b[K\rremote: Counting objects:  49% (261/532)\u001b[K\rremote: Counting objects:  50% (266/532)\u001b[K\rremote: Counting objects:  51% (272/532)\u001b[K\rremote: Counting objects:  52% (277/532)\u001b[K\rremote: Counting objects:  53% (282/532)\u001b[K\rremote: Counting objects:  54% (288/532)\u001b[K\rremote: Counting objects:  55% (293/532)\u001b[K\rremote: Counting objects:  56% (298/532)\u001b[K\rremote: Counting objects:  57% (304/532)\u001b[K\rremote: Counting objects:  58% (309/532)\u001b[K\rremote: Counting objects:  59% (314/532)\u001b[K\rremote: Counting objects:  60% (320/532)\u001b[K\rremote: Counting objects:  61% (325/532)\u001b[K\rremote: Counting objects:  62% (330/532)\u001b[K\rremote: Counting objects:  63% (336/532)\u001b[K\rremote: Counting objects:  64% (341/532)\u001b[K\rremote: Counting objects:  65% (346/532)\u001b[K\rremote: Counting objects:  66% (352/532)\u001b[K\rremote: Counting objects:  67% (357/532)\u001b[K\rremote: Counting objects:  68% (362/532)\u001b[K\rremote: Counting objects:  69% (368/532)\u001b[K\rremote: Counting objects:  70% (373/532)\u001b[K\rremote: Counting objects:  71% (378/532)\u001b[K\rremote: Counting objects:  72% (384/532)\u001b[K\rremote: Counting objects:  73% (389/532)\u001b[K\rremote: Counting objects:  74% (394/532)\u001b[K\rremote: Counting objects:  75% (399/532)\u001b[K\rremote: Counting objects:  76% (405/532)\u001b[K\rremote: Counting objects:  77% (410/532)\u001b[K\rremote: Counting objects:  78% (415/532)\u001b[K\rremote: Counting objects:  79% (421/532)\u001b[K\rremote: Counting objects:  80% (426/532)\u001b[K\rremote: Counting objects:  81% (431/532)\u001b[K\rremote: Counting objects:  82% (437/532)\u001b[K\rremote: Counting objects:  83% (442/532)\u001b[K\rremote: Counting objects:  84% (447/532)\u001b[K\rremote: Counting objects:  85% (453/532)\u001b[K\rremote: Counting objects:  86% (458/532)\u001b[K\rremote: Counting objects:  87% (463/532)\u001b[K\rremote: Counting objects:  88% (469/532)\u001b[K\rremote: Counting objects:  89% (474/532)\u001b[K\rremote: Counting objects:  90% (479/532)\u001b[K\rremote: Counting objects:  91% (485/532)\u001b[K\rremote: Counting objects:  92% (490/532)\u001b[K\rremote: Counting objects:  93% (495/532)\u001b[K\rremote: Counting objects:  94% (501/532)\u001b[K\rremote: Counting objects:  95% (506/532)\u001b[K\rremote: Counting objects:  96% (511/532)\u001b[K\rremote: Counting objects:  97% (517/532)\u001b[K\rremote: Counting objects:  98% (522/532)\u001b[K\rremote: Counting objects:  99% (527/532)\u001b[K\rremote: Counting objects: 100% (532/532)\u001b[K\rremote: Counting objects: 100% (532/532), done.\u001b[K\n","remote: Compressing objects: 100% (532/532), done.\u001b[K\n","remote: Total 532 (delta 0), reused 532 (delta 0), pack-reused 0\u001b[K\n","Receiving objects: 100% (532/532), 27.17 MiB | 22.11 MiB/s, done.\n","Cloning into 'models'...\n","remote: Enumerating objects: 32650, done.\u001b[K\n","remote: Total 32650 (delta 0), reused 0 (delta 0), pack-reused 32650\u001b[K\n","Receiving objects: 100% (32650/32650), 511.53 MiB | 37.90 MiB/s, done.\n","Resolving deltas: 100% (20783/20783), done.\n","Checking out files: 100% (3174/3174), done.\n","Cloning into 'create_tfrecords'...\n","remote: Enumerating objects: 3, done.\u001b[K\n","remote: Counting objects: 100% (3/3), done.\u001b[K\n","remote: Compressing objects: 100% (3/3), done.\u001b[K\n","remote: Total 65 (delta 0), reused 0 (delta 0), pack-reused 62\u001b[K\n","Unpacking objects: 100% (65/65), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"N67ijrCKjKR2","colab_type":"code","outputId":"e6a4b599-19a3-41af-cfb6-03a8256ad904","executionInfo":{"status":"ok","timestamp":1574162580749,"user_tz":-330,"elapsed":4241,"user":{"displayName":"Saisharan K","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAJ1nwvSoqQU5GIyVGpz9V4iq_C1Cv8tEYDhBHRPw=s64","userId":"06407441015676207791"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/models/research/slim/datasets\n","!touch hp_plants.py"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/content/models/research/slim/datasets\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kAJjiSewjNMb","colab_type":"code","outputId":"bf57ff86-996a-4a0a-92c5-5d436301faa6","executionInfo":{"status":"ok","timestamp":1574096370941,"user_tz":-330,"elapsed":36780,"user":{"displayName":"Saisharan K","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAJ1nwvSoqQU5GIyVGpz9V4iq_C1Cv8tEYDhBHRPw=s64","userId":"06407441015676207791"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"y628O3kxjY0l","colab_type":"code","outputId":"5cfe5df1-ee89-40da-d5a0-5f685b6cd22d","executionInfo":{"status":"ok","timestamp":1574162734720,"user_tz":-330,"elapsed":9101,"user":{"displayName":"Saisharan K","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAJ1nwvSoqQU5GIyVGpz9V4iq_C1Cv8tEYDhBHRPw=s64","userId":"06407441015676207791"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["!python3 /content/create_tfrecords/create_tfrecord.py --dataset_dir=/content/Left-and-Right --tfrecord_filename=leftright --validation_size=0.2"],"execution_count":4,"outputs":[{"output_type":"stream","text":["WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From /content/create_tfrecords/dataset_utils.py:213: The name tf.gfile.Exists is deprecated. Please use tf.io.gfile.exists instead.\n","\n","WARNING:tensorflow:From /content/create_tfrecords/dataset_utils.py:106: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/create_tfrecords/dataset_utils.py:180: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2019-11-19 11:25:30.815505: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2019-11-19 11:25:30.864535: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:30.865181: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2019-11-19 11:25:30.879134: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2019-11-19 11:25:31.073262: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2019-11-19 11:25:31.229264: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2019-11-19 11:25:31.255282: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2019-11-19 11:25:31.491761: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2019-11-19 11:25:31.531279: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2019-11-19 11:25:31.934403: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2019-11-19 11:25:31.934635: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:31.935290: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:31.935836: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2019-11-19 11:25:31.936345: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX512F\n","2019-11-19 11:25:31.967164: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2000179999 Hz\n","2019-11-19 11:25:31.970726: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22f7100 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2019-11-19 11:25:31.970759: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2019-11-19 11:25:32.101701: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:32.102377: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x22f72c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2019-11-19 11:25:32.102409: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2019-11-19 11:25:32.103755: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:32.104304: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2019-11-19 11:25:32.104365: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2019-11-19 11:25:32.104383: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2019-11-19 11:25:32.104396: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2019-11-19 11:25:32.104408: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2019-11-19 11:25:32.104424: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2019-11-19 11:25:32.104436: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2019-11-19 11:25:32.104449: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2019-11-19 11:25:32.104494: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:32.105012: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:32.105472: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2019-11-19 11:25:32.111268: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2019-11-19 11:25:32.112680: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2019-11-19 11:25:32.112709: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2019-11-19 11:25:32.112721: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2019-11-19 11:25:32.113927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:32.114530: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2019-11-19 11:25:32.115095: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2019-11-19 11:25:32.115132: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/create_tfrecords/dataset_utils.py:186: The name tf.python_io.TFRecordWriter is deprecated. Please use tf.io.TFRecordWriter instead.\n","\n",">> Converting image 1/16 shard 0WARNING:tensorflow:From /content/create_tfrecords/dataset_utils.py:195: FastGFile.__init__ (from tensorflow.python.platform.gfile) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.gfile.GFile.\n","Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1365, in _do_call\n","    return fn(*args)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1350, in _run_fn\n","    target_list, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1443, in _call_tf_sessionrun\n","    run_metadata)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '#!/bin/sh\\n#\\n# An'\n","\t [[{{node DecodeJpeg}}]]\n","\n","During handling of the above exception, another exception occurred:\n","\n","Traceback (most recent call last):\n","  File \"/content/create_tfrecords/create_tfrecord.py\", line 70, in <module>\n","    main()\n","  File \"/content/create_tfrecords/create_tfrecord.py\", line 59, in main\n","    dataset_dir = FLAGS.dataset_dir, tfrecord_filename = FLAGS.tfrecord_filename, _NUM_SHARDS = FLAGS.num_shards)\n","  File \"/content/create_tfrecords/dataset_utils.py\", line 196, in _convert_dataset\n","    height, width = image_reader.read_image_dims(sess, image_data)\n","  File \"/content/create_tfrecords/dataset_utils.py\", line 110, in read_image_dims\n","    image = self.decode_jpeg(sess, image_data)\n","  File \"/content/create_tfrecords/dataset_utils.py\", line 115, in decode_jpeg\n","    feed_dict={self._decode_jpeg_data: image_data})\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 956, in run\n","    run_metadata_ptr)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1180, in _run\n","    feed_dict_tensor, options, run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1359, in _do_run\n","    run_metadata)\n","  File \"/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\", line 1384, in _do_call\n","    raise type(e)(node_def, op, message)\n","tensorflow.python.framework.errors_impl.InvalidArgumentError: Expected image (JPEG, PNG, or GIF), got unknown format starting with '#!/bin/sh\\n#\\n# An'\n","\t [[node DecodeJpeg (defined at usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py:1748) ]]\n","\n","Original stack trace for 'DecodeJpeg':\n","  File \"content/create_tfrecords/create_tfrecord.py\", line 70, in <module>\n","    main()\n","  File \"content/create_tfrecords/create_tfrecord.py\", line 59, in main\n","    dataset_dir = FLAGS.dataset_dir, tfrecord_filename = FLAGS.tfrecord_filename, _NUM_SHARDS = FLAGS.num_shards)\n","  File \"content/create_tfrecords/dataset_utils.py\", line 178, in _convert_dataset\n","    image_reader = ImageReader()\n","  File \"content/create_tfrecords/dataset_utils.py\", line 107, in __init__\n","    self._decode_jpeg = tf.image.decode_jpeg(self._decode_jpeg_data, channels=3)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/gen_image_ops.py\", line 1211, in decode_jpeg\n","    dct_method=dct_method, name=name)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/op_def_library.py\", line 794, in _apply_op_helper\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\", line 507, in new_func\n","    return func(*args, **kwargs)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3357, in create_op\n","    attrs, op_def, compute_device)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 3426, in _create_op_internal\n","    op_def=op_def)\n","  File \"usr/local/lib/python3.6/dist-packages/tensorflow_core/python/framework/ops.py\", line 1748, in __init__\n","    self._traceback = tf_stack.extract_stack()\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zE6N0P36jkim","colab_type":"code","colab":{}},"source":["train_data_dir = '/content/sides/training'\n","validation_data_dir = '/content/sides/testing'\n","nb_train_samples = 2000\n","nb_validation_samples = 800\n","epochs = 300\n","batch_size = 32"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"5pEJAs0ZFPke","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2sn3yXiAjvz4","colab_type":"code","colab":{}},"source":["base_model=InceptionV3(input_shape=(224,224,3),weights='imagenet',include_top=False) #imports the inceptionResNetV2 model and discards the last 1000 neuron layer.\n","x=base_model.output\n","x=GlobalAveragePooling2D()(x)\n","x=Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.001))(x) #we add dense layers so that the model can learn more complex functions and classify for better results.\n","x=Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.001))(x) #dense layer 2\n","x=Dropout(0.2)(x)\n","x=Dense(512,activation='relu',kernel_regularizer=regularizers.l2(0.001))(x) #dense layer 3\n","preds=Dense(2,activation='softmax',kernel_regularizer=regularizers.l2(0.001))(x) #final layer with softmax activation"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V-m6ye1cj8RQ","colab_type":"code","colab":{}},"source":["model=Model(inputs=base_model.input,outputs=preds)\n","#specify the inputs\n","#specify the outputs\n","#now a model has been created based on our architecture"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KbE_ddgpke1J","colab_type":"code","colab":{}},"source":["for i,layer in enumerate(model.layers):\n","  print(i,layer.name)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UybH90G4kjTQ","colab_type":"code","colab":{}},"source":["#if we want to set the first 20 layers of the network to be non-trainable\n","for layer in model.layers[:20]:\n","  layer.trainable=False\n","for layer in model.layers[20:]:\n","  layer.trainable=True"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g2b7SfRBknTq","colab_type":"code","colab":{}},"source":["# this is the augmentation configuration we will use for training\n","train_datagen = ImageDataGenerator(rescale=1. / 255)\n","# this is the augmentation configuration we will use for testing:\n","# only rescaling\n","test_datagen = ImageDataGenerator(rescale=1. / 255)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2XUxBQCTl8Mb","colab_type":"code","colab":{}},"source":["train_generator = train_datagen.flow_from_directory(train_data_dir, target_size=(img_width, img_height), \n","                                                    batch_size=batch_size, class_mode='categorical')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fGw47JqzmBwI","colab_type":"code","colab":{}},"source":["validation_generator = test_datagen.flow_from_directory(validation_data_dir, target_size=(img_width, img_height),\n","                                                        batch_size=batch_size, class_mode='categorical')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"UWU2INEemTCX","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","savepath = os.path.join( \"\"+ 'e1-{epoch:03d}-vl-{val_loss:.3f}-va-{val_acc:.3f}.h5' )\n","checkpointer = ModelCheckpoint(filepath=savepath)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"94KM249TKhlo","colab_type":"code","colab":{}},"source":["model.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JeNJvOfXmYBv","colab_type":"code","colab":{}},"source":["model.compile(optimizer='Adam',loss='categorical_crossentropy',metrics=['accuracy'])\n","# Adam optimizer\n","# loss function will be categorical cross entropy\n","# evaluation metric will be accuracy\n","\n","#step_size_train=train_generator.n//train_generator.batch_size\n","step_size_train=4000 // batch_size\n","\n","history = model.fit_generator(generator=train_generator, steps_per_epoch=step_size_train, epochs = epochs, validation_steps=800 // batch_size,\n","                              validation_data=validation_generator,callbacks=[checkpointer])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_EVpxVBJK8QH","colab_type":"code","colab":{}},"source":["%matplotlib inline\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.image as mpimg\n","\n","# Retrieve a list of accuracy results on training and validation data\n","# sets for each training epoch\n","acc = history.history['acc']\n","val_acc = history.history['val_acc']\n","\n","# Retrieve a list of list results on training and validation data\n","# sets for each training epoch\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","# Get number of epochs\n","epochs = range(len(acc))\n","\n","# Plot training and validation accuracy per epoch\n","plt.plot(epochs, acc)\n","plt.plot(epochs, val_acc)\n","plt.title('Training and validation accuracy')\n","\n","plt.figure()\n","\n","# Plot training and validation loss per epoch\n","plt.plot(epochs, loss)\n","plt.plot(epochs, val_loss)\n","plt.title('Training and validation loss')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"E_nSufjZMbwP","colab_type":"code","colab":{}},"source":[" import os\n","import os.path as osp\n","import argparse\n","\n","import tensorflow as tf\n","\n","from keras.models import load_model\n","from keras import backend as K\n","\n","\n","\n","\n","def convertGraph( modelPath, outdir, numoutputs, prefix, name):\n","    '''\n","    Converts an HD5F file to a .pb file for use with Tensorflow.\n","    Args:\n","        modelPath (str): path to the .h5 file\n","           outdir (str): path to the output directory\n","       numoutputs (int):   \n","           prefix (str): the prefix of the output aliasing\n","             name (str):\n","    Returns:\n","        None\n","    '''\n","    \n","    #NOTE: If using Python > 3.2, this could be replaced with os.makedirs( name, exist_ok=True )\n","    if not os.path.isdir(outdir):\n","        os.mkdir(outdir)\n","\n","    K.set_learning_phase(0)\n","\n","    net_model = load_model(modelPath)\n","\n","    # Alias the outputs in the model - this sometimes makes them easier to access in TF\n","    pred = [None]*numoutputs\n","    pred_node_names = [None]*numoutputs\n","    for i in range(numoutputs):\n","        pred_node_names[i] = prefix+'_'+str(i)\n","        pred[i] = tf.identity(net_model.output[i], name=pred_node_names[i])\n","    print('Output nodes names are: ', pred_node_names)\n","\n","    sess = K.get_session()\n","    \n","    # Write the graph in human readable\n","    f = 'graph_def_for_reference.pb.ascii'\n","    tf.train.write_graph(sess.graph.as_graph_def(), outdir, f, as_text=True)\n","    print('Saved the graph definition in ascii format at: ', osp.join(outdir, f))\n","\n","    # Write the graph in binary .pb file\n","    from tensorflow.python.framework import graph_util\n","    from tensorflow.python.framework import graph_io\n","    constant_graph = graph_util.convert_variables_to_constants(sess, sess.graph.as_graph_def(), pred_node_names)\n","    graph_io.write_graph(constant_graph, outdir, name, as_text=False)\n","    print('Saved the constant graph (ready for inference) at: ', osp.join(outdir, name))\n","\n","convertGraph( \"/content/e1-015-vl-0.497-va-0.885.h5\", \"/content/\", 1,'output', 'output_graph.pb' )\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RaEpZUxJMu1-","colab_type":"code","colab":{}},"source":["\n","import tensorflow as tf\n","from tensorflow import lite\n","\n","print( tf.VERSION )\n","#converter = lite.TFLiteConverter.from_keras_model_file( '/content/sides/e1-001-vl-2.491-va-0.472.h5' ) \n","input_arrays = [\"input_1_1\"]\n","output_arrays = [\"output_0\"]\n","\n","converter = lite.TFLiteConverter.from_keras_model_file( '/content/e1-015-vl-0.497-va-0.885.h5' ) \n","tflite_model = converter.convert()\n","open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n","interpreter = lite.Interpreter(model_path=\"/content/converted_model.tflite\")\n","print(interpreter.get_output_details()[0]['shape'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3izMo6AYMzXo","colab_type":"code","colab":{}},"source":["import tensorflow as tf\n","from tensorflow.python.platform import gfile\n","\n","f = gfile.FastGFile(\"/content/output_graph.pb\", 'rb')\n","graph_def = tf.GraphDef()\n","# Parses a serialized binary message into the current message.\n","graph_def.ParseFromString(f.read())\n","f.close()\n","\n","#sess.graph.as_default()\n","# Import a serialized TensorFlow `GraphDef` protocol buffer\n","# and place into the current default `Graph`.\n","tf.import_graph_def(graph_def)\n","print('Check out the input placeholders:')\n","nodes = [n.name + ' => ' +  n.op for n in graph_def.node if n.op in ('Placeholder')]\n","for node in nodes:\n","    print(node)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wNpqFAN-AEZC","colab_type":"code","colab":{}},"source":[" model.save_weights('first_try.h5')"],"execution_count":0,"outputs":[]}]}